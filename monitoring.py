# import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sb
import matplotlib.pyplot as plt
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from feature_engine.outliers import Winsorizer
from sklearn.model_selection import train_test_split
import dtale
import pickle, joblib
from sqlalchemy import create_engine, text
from urllib.parse import quote


#lets import the data
df = pd.read_csv(r"C:/Users/ganes/OneDrive/Desktop/Proj/360digiTMG/Folder/prima_13.csv")

print(df)

df.info()
# autoeda
dtale.show(df).open_browser()

#Descriptive Analytics
desc = df.describe()

df=df.rename(columns={
            "Hydraulic_Pressure(bar)": "Hydraulic_Pressure_bar",
            "Coolant_Pressure(bar)": "Coolant_Pressure_bar",
            "Air_System_Pressure(bar)": "Air_System_Pressure_bar",
            "Coolant_Temperature(°C)": "Coolant_Temperature_C",
            "Hydraulic_Oil_Temperature(°C)": "Hydraulic_Oil_Temperature_C",
            "Spindle_Vibration(µm)": "Spindle_Vibration_um",
            "Tool_Vibration(µm)": "Tool_Vibration_um",
            "Spindle_Speed(RPM)": "Spindle_Speed_RPM",
            "Voltage(volts)": "Voltage_volts",
            "Cutting_Force(kN)": "Cutting_Force_kN"
        })

# Datapreprocessing by Pipeline
df.columns
# Seperating input and output variables 
df_x = df.drop(['Date', 'Machine_ID', 'Downtime'], axis = 1)
df_y = df[['Downtime']]

# All numeric features
numeric_features = df_x.select_dtypes(exclude = ['object']).columns
numeric_features

# All categorical features
categorical_features = df_x.select_dtypes(include = ['object']).columns
categorical_features# No Categorical features in predictors

# Imputation strategy for numeric columns
num_pipeline = Pipeline([('impute', SimpleImputer(strategy = 'mean')),('scale', MinMaxScaler())])
                                                  
# Using ColumnTransfer to transform the columns of an array or pandas DataFrame. This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space.
preprocess_pipeline = ColumnTransformer([('numerical', num_pipeline, numeric_features)])

processed = preprocess_pipeline.fit(df_x)  # Pass the raw data through pipeline

processed

# Save the defined pipeline
joblib.dump(processed, 'imp_scale')

import os 
os.getcwd()

# Transform the original data using the pipeline defined above
cleandata = pd.DataFrame(processed.transform(df_x), columns = processed.get_feature_names_out())  # Clean and processed data for Clustering

cleandata.info()

# columns list
columns_list = list(cleandata.columns)
columns_list

########## Boxplot before cleaning
ax = cleandata.plot(kind='box', subplots=True, sharey=False, figsize=(40, 18))
# Set x-axis labels rotation and fontsize for each subplot
for subplot in ax:
    subplot.set_xticklabels(subplot.get_xticklabels(), rotation=90, fontsize=21)
# Adjust the spacing between subplots
plt.subplots_adjust(wspace=1.0)
# Show the plot
plt.show()

##########
winsor = Winsorizer(capping_method = 'iqr', # choose  IQR rule boundaries or gaussian for mean and std
                          tail = 'both', # cap left, right or both tails 
                          fold = 1.5,
                          variables = columns_list)

# Fit the winsorizer to numerical columns
outlier = winsor.fit(cleandata[columns_list])
# Save the fitted winsorizer model 
joblib.dump(outlier, 'winsor')
cleandata[columns_list] = outlier.transform(cleandata[columns_list])

########## Boxplot after cleaning
ax = cleandata.plot(kind='box', subplots=True, sharey=False, figsize=(40, 18))
# Set x-axis labels rotation and fontsize for each subplot
for subplot in ax:
    subplot.set_xticklabels(subplot.get_xticklabels(), rotation=90, fontsize=21)
# Adjust the spacing between subplots
plt.subplots_adjust(wspace=1.0)
# Show the plot
plt.show()

### check for balanced or imbalanced data
df_y['Downtime'].value_counts()

# The ratio of NON_FAILURE to FAILURE can be calculated as:
# 2400 / 300 = 8
# This means that there are 8 times more instances of NON_FAILURE than FAILURE in dataset.
# When the ratio of instances between the classes is significantly imbalanced, as in this case, 
# the data is considered imbalanced.

from imblearn.over_sampling import SMOTE
smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(cleandata, df_y)
X_resampled.shape
y_resampled.shape
y_resampled['Downtime'].value_counts()

# split data
X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, y_resampled, test_size = 0.2, random_state = 0, stratify = y_resampled)
# X_train, X_test, Y_train, Y_test = train_test_split(cleandata, df_y, test_size = 0.2, random_state = 0, stratify = df_y)

X_train.shape
X_test.shape
Y_train.value_counts()
Y_test.value_counts()


# Model building
# Best Model
############ Naive bayes from Automl Pycarret
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report

Gausian = GaussianNB(priors=None, var_smoothing=1e-09)

model_nb = Gausian.fit(X_train.values, Y_train.values.ravel())

pred = model_nb.predict(X_train.values)

accuracy = accuracy_score(Y_train, pred)
print("Test Accuracy:", accuracy)

report = classification_report(Y_train, pred)
print("Classification Report:\n", report)
####
pred_test = model_nb.predict(X_test.values)

# Evaluate the model's performance
accuracy = accuracy_score(Y_test, pred_test)
print("Test Accuracy:", accuracy)

report = classification_report(Y_test, pred_test)
print("Classification Report:\n", report)


pickle.dump(model_nb, open('Naive_bayes.pkl','wb'))


import evidently
evidently.__version__

from evidently.test_suite import TestSuite
from evidently.tests import *
from evidently.metrics import *
from evidently.report import Report
from evidently.metric_preset  import TargetDriftPreset
from evidently import ColumnMapping

X_train['target']=Y_train
X_train['prediction']=pred

X_test['target']=Y_test
X_test['prediction']=pred_test
target='Downtime'
column_mapping=ColumnMapping()
column_mapping.target=target
column_mapping.prediction='prediction'
column_mapping.numeric_features=numeric_features
column_mapping.categorical_features=categorical_features


data_integrity_dataset_tests=TestSuite(tests=[
    TestNumberOfColumns(),
    TestNumberOfRows(),
    TestNumberOfMissingValues(),
    TestShareOfMissingValues(),
    TestNumberOfColumnsWithMissingValues(),
    TestNumberOfRowsWithMissingValues(),
    TestNumberOfDifferentMissingValues(),
    TestNumberOfConstantColumns(),
    TestNumberOfEmptyRows(),
    TestNumberOfEmptyColumns(),
    TestNumberOfDuplicatedColumns(),
    TestNumberOfDuplicatedRows(),
    TestColumnsType(),])
# Check if 'Downtime' column is present in X_train and X_test

data_integrity_dataset_tests.run(reference_data=X_train,current_data=X_test)

data_integrity_dataset_tests.save_html('data_integrity_dataset_tests_report.html')

data_quality_dataset_tests=TestSuite(tests=[
    TestConflictTarget(),
    TestConflictPrediction(),
    TestTargetPredictionCorrelation(),
    TestHighlyCorrelatedColumns(),
    TestTargetFeaturesCorrelations(),
    TestPredictionFeaturesCorrelations(),
    TestCorrelationChanges(),
])

data_quality_dataset_tests.run(reference_data=X_train,current_data=X_test)
data_quality_dataset_tests.save_html('data_quality_dataset_tests_report.html')
                                     

data_drift_dataset_report=Report(metrics=[
        DataDriftTable(num_stattest='kl_div',cat_stattest='psi'),])

data_drift_dataset_report.run(reference_data=X_train,current_data=X_test)
data_drift_dataset_report.save_html('data_drift_dataset_report.html')

data_drift_column_report=Report(metrics=[
    ColumnDriftMetric('numerical__Torque'),ColumnValuePlot('numerical__Torque'),])

data_drift_column_report.run(reference_data=X_train,current_data=X_test)
data_drift_column_report.save_html('data_drift_column_report.html')

from evidently.test_preset import DataStabilityTestPreset
from evidently.test_preset import DataQualityTestPreset
from evidently.test_preset import DataDriftTestPreset
from evidently.test_preset import BinaryClassificationTestPreset

from evidently.test_preset import NoTargetPerformanceTestPreset
from evidently.test_preset import BinaryClassificationTopKTestPreset

data_stability=TestSuite(tests=[DataStabilityTestPreset(),])
data_stability.run(reference_data=X_train,current_data=X_test)
data_stability.save_html('data_stability_report.html')
data_stability.json()
sample_dict=data_stability.as_dict()


data_quality=TestSuite(tests=[DataQualityTestPreset(),])